{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876cac2-7253-4300-af6d-750690df74c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lab3: Sequential Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad5672a-d253-4e57-b051-2bac331e589a",
   "metadata": {},
   "source": [
    "Importing Packages and libraries to run the codes.\n",
    "\n",
    "It importing python Operating System.\n",
    "\n",
    "TF(Tensor flow) control the amount of logging output printed to the console.\n",
    "\n",
    "By importing karas its runs top TF& deep learning frames.\n",
    "\n",
    "Sklearn imports performs the deep learning tasks,like classification & regression.\n",
    "\n",
    "The Skl learn-model-selection for spliting data sets in to training tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7ef17-b004-418d-bea3-fa723d1d887a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# disable tensorflow printing messages to the standard output\n",
    "# 3 = INFO, WARNING, and ERROR messages are NOT printed\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb32beb-af4a-4c57-a5b5-457d2ff76db4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here it gets and read the file from iris.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789de289-bad1-4199-b222-1dcdcd6022ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390c43-4625-4c0c-b902-19e5b3613622",
   "metadata": {
    "tags": []
   },
   "source": [
    "By using the head command its display first 5 rows of data frames and columns allows to inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aa287f-4eb1-45a2-91c5-a7342ceb3cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31077626-69fd-4930-a7e4-21f55e6731d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "The df.shape attribute is used to determine the dimensions of data frame.It produce the output by represents the no.of rows and columns in a tuple format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd17852-d6fb-4130-9dd0-4995361f6f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20089794-e176-4e31-98cd-de67b1c0f7b4",
   "metadata": {},
   "source": [
    "The info() method prints information about the DataFrame. \n",
    "It produce information based on the No.of Columns, data types, range of index,No.of cells in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3718c44-a29c-4a06-bcf2-7aa8851b21e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6235b381-dd2f-47e9-9da0-89a6d622647c",
   "metadata": {},
   "source": [
    "The describe() method returns description of the data in the DataFrame.\n",
    "information of numerical data & each column details like count of non empty values, The average mean value.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d311a0-011c-4dc7-91cf-eecaf96ed1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e97b21-6841-4bd3-9432-dab10d9170d3",
   "metadata": {},
   "source": [
    "Here the iris Load and return the iris dataset (classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea28242-4521-4eca-a91c-5ca12b92a785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b19b2-0535-411f-854a-e01e5d94c132",
   "metadata": {},
   "source": [
    "Now it excute the data frame and load data type in iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891f1da-2cac-45e7-865d-a932682abeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489f5d3-0f4a-4038-a84e-93206fab208b",
   "metadata": {},
   "source": [
    "#### For more info of 'Bunch', see the scikit-learn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e968528-a199-407c-9581-1d02c234bab5",
   "metadata": {},
   "source": [
    "The dataset contains some keys, which we can use to access specific data.Suppose you want get the data about the iris data, you can specify iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5d2f8-bbdc-4fae-987f-4fcb0c102d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5bf715-aa0d-4e4a-83be-d5f78b522c40",
   "metadata": {},
   "source": [
    "values attribute to obtain a NumPy array containing the values of the dataset. In each row the array represents the each column with a feature like length, width, of iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f22bb-b1f5-41a6-a425-bda6490d8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a71ab-6001-447c-b574-dc955189a65e",
   "metadata": {
    "tags": []
   },
   "source": [
    "It looks like  to extract the feature data from the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566920b-e4b6-4763-9116-3b0760d40d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbbd32-9a0a-4647-ab2b-4b0aba86c0e4",
   "metadata": {},
   "source": [
    "The type(features) will return <class 'numpy.ndarray'>,it shows the features variable contains a NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cbba0-133e-4b36-9026-0f91c5af5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64acdbf1-2d38-4c55-bf18-338787964919",
   "metadata": {},
   "source": [
    "By using target method to extract the target labels from the Iris dataset by using Iris dataset loaded using Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b193663-76db-40dd-bb54-918f885f1142",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebc462a-edf6-4d6d-8277-9629fe57205f",
   "metadata": {},
   "source": [
    "The type(target)it return <class 'numpy.ndarray'>, indicating that the target variable contains a NumPy array. This NumPy array holds the target labels from the Iris dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525c509-0907-4bcb-abc9-47c780d2a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adecb4-74dc-447c-a16c-10a07e5d1423",
   "metadata": {},
   "source": [
    "Go through the for loop and iterate through the target names in the Iris dataset and print them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb33e91-cd8e-4e12-94c3-4820bfb4ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for flower in iris['target_names']:\n",
    "    print(flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec15dcb-fd8e-45ef-8826-22d6320738c9",
   "metadata": {},
   "source": [
    "#### Another way to print out the flower names is with a list comprehension.\n",
    "\n",
    "`target_names = [flower for flower in iris['target_names']] # create a list of flower names`\n",
    "\n",
    "`print(target_names)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4551a5-48ea-4244-b59c-5e514bb19920",
   "metadata": {},
   "source": [
    "the numerical class labels stored in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49502fe6-ed94-483d-b931-5187b2fc1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437927c-c710-438b-bfc1-6adf11ddd9ca",
   "metadata": {},
   "source": [
    "This code will print the feature names from the Iris dataset. which reperesents the measurments of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d8cfd-fe70-4880-91e3-b2b65275eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([feature for feature in iris['feature_names']])\n",
    "# for feature in iris['feature_names']:\n",
    "#     print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb306a-1e33-41b7-877c-d719af016a5f",
   "metadata": {},
   "source": [
    "Its Using index slicing of features to print feauters from index 0 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfa6e6-44e7-4781-9a9f-8cd7584a5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14df87-fbaa-494a-bd70-8693ba809f2e",
   "metadata": {},
   "source": [
    "The code is used to determine the shape (dimensionality) of the feature vector for the first   sample in the Iris dataset. \n",
    "It will return (4,), indicating that the feature vector for the first sample has four   dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929dc80a-587c-4106-ba4b-34b3e29b260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1f304-0101-491b-abb1-4e3eea1a65e4",
   "metadata": {},
   "source": [
    " which is splitting the Iris dataset into training and testing sets while specifying the test size and setting a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd686c80-9ac5-400c-8cf5-d2a4105c4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = sklearn.model_selection.train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7116f-ac65-465a-8173-487d3ed3736d",
   "metadata": {},
   "source": [
    " The code is using to convert the target labels into a binary matrix representation suitable for multi-class classification, where number_classes indicates the total number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f76a4f-58d5-4e5f-b8d0-45ea2cd4ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 3\n",
    "target_train = keras.utils.to_categorical(target_train, number_classes)\n",
    "target_test = keras.utils.to_categorical(target_test, number_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d87eb-2cf3-4c2a-862a-62a69426cf11",
   "metadata": {},
   "source": [
    "Creating a feedforward neural network model with 3 layers: two hidden layers with ReLU activation. its taking 64 inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b349b34-f72e-47ba-a8d0-0445503617e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"relu\", input_shape=(4,)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62252063-4023-4552-a074-c27eebbfe3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compiling the neural network model with categorical crossentropy loss, the Adam optimizer, and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6db7c-1f20-4131-b37d-349a9c8475a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da592af6-57b7-44e3-8489-dea0a7011a66",
   "metadata": {
    "tags": []
   },
   "source": [
    "This model using the specified training data, batch size, and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b264acb-2b8d-455c-afef-4cd37e066e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(features_train, target_train,\n",
    "          batch_size=64, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a316ad4-fd44-4e15-ad80-cc6c992b1316",
   "metadata": {},
   "source": [
    "Evaluating the trained model on the test dataset and displaying the test loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf611d0-b24f-4d47-9208-807b22ab2ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(features_test, target_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c06e69-75cb-46cf-8c56-6693044fce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### All students, answer the following:\n",
    "\n",
    "#### 1. What is the importance of a feature for machine learning?\n",
    "\n",
    "#### 2. How many unique features are present in the Iris dataset? Justify your answer.\n",
    "\n",
    "#### 3. How many neurons are in the input layer? Justify your answer.\n",
    "\n",
    "#### 4. What is an epoch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63140613-2f4e-4750-8e49-29f0dc412cef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### All students, answer the following:\n",
    "\n",
    "#### 1. What is the importance of a feature for machine learning?\n",
    " Features are also Variables,These features are generated from a data set and used as input to machine learning Models.it indicates that how much feature contributes to the prediction.\n",
    "Example:\n",
    "Suppose, if you want to predict the height based on the weight of person and name of the person, Features that the variable height will have strongest influence.While the name is not relavent to the person height.\n",
    "\n",
    "#### 2. How many unique features are present in the Iris dataset? Justify your answer.\n",
    "To determine the number of unique features in the Iris dataset, we can analyze these four measurements:\n",
    "Sepal length,Sepal width,Petal length,Petal width\n",
    "Each of these four measurements represents a unique feature in the dataset. Therefore, there are four unique features present in the Iris dataset.\n",
    "#### 3. How many neurons are in the input layer? Justify your answer.\n",
    "They are four neurons in the input layer of a nueral network for ths iris dataset, they are four features in the data set, and each neuron corresponds to the each features.\n",
    "#### 4. What is an epoch?\n",
    " An \"Epoch\" is refers to one complete cycle through the entire training dataset during the running of a machine learning model.\n",
    " It improves the the ability and make accurate predictions on unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc263d-c51b-4a84-88c9-200d7eab5695",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Graduate students only:\n",
    "\n",
    "#### 5. Why doesn't the class appear in `df.describe()`?\n",
    "The 'df.describe()' method is in pandas its, used to generate the statistics summary of  numerical columns in a dataFrame,like a count,mean, standard deviation,minimum, and maximum values.\n",
    "The'df.describe'is not include the non_numeric or categorical columns, including class labels.\n",
    "In class labels typically dont have meaningful statistical like mean or standard deviation.\n",
    "\n",
    "\n",
    "#### 6. What other datasets does scikit-learn support with their `datasets` module? How do you know?\n",
    "scikit-learn (sklearn) provides a collection of datasets through its datasets module. These datasets are commonly used for machine learning experimentation and practice. \n",
    "\n",
    "Iris Dataset: A classic dataset for classification, containing measurements of iris flowers' features and their species labels.\n",
    "\n",
    "#### 7. Review the loss and accuracy of the model.\n",
    "- If the accuracy is not 100%, how could you improve the accuracy of the model?\n",
    "To improve model accuracy when its not 100%:\n",
    "\n",
    "Provide the better representation of code with clean data, scale and features or variables.\n",
    "Try to implement the various methods and different algorithms and adjus the parameters, dimensions.\n",
    "To prevent overfitting apply different techniques.\n",
    "Collect the data if more possible.\n",
    "Data Augmentation for image / text data enchance variety.\n",
    "- Why should or shouldn't you strive for 100% accuracy and near zero loss?\n",
    "In practical world , its not possible to get 100 % accuracy beacuse contain noise & variability.\n",
    "Striving 100 per can lead to overfitting, model is too specific to the training data.\n",
    "To Acheive it to consider the available resources,trade-offs, balancing perfection with practical limitations.\n",
    "\n",
    "\n",
    "#### 8. In the call to compile the model, what does \"adam\" stand for in the optimizer argument? Justify your answer.\n",
    "\n",
    " \"Adam\" stands for \"Adaptive Moment Estimation.\" It is an optimization algorithm commonly used for training neural networks.\n",
    " Adam\"which can lead to faster convergence during training and better handling of noisy gradients. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd14bda-1399-4937-b759-90caccb3d603",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq-nn:Python",
   "language": "python",
   "name": "conda-env-seq-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
